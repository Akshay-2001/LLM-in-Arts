{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU torch torchvision torchaudio transformers accelerate peft datasets scikit-learn pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF2ajIt2ZMmF",
        "outputId": "297edc99-6e00-4f37-b990-e1ec20471607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd5LjhAkY6ee",
        "outputId": "5e966920-3f2c-471d-c955-6dff3e011c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/NLP/Datasets/lyrics_song_info.csv\")\n",
        "\n",
        "df = df.dropna(subset=[\"lyrics\", \"tags\"])\n",
        "\n",
        "df[\"primary_genre\"] = df[\"tags\"].str.split(\";\").str[0]\n",
        "\n",
        "TOP_N = 100\n",
        "top_genres = df[\"primary_genre\"].value_counts().nlargest(TOP_N).index\n",
        "df = df[df[\"primary_genre\"].isin(top_genres)].reset_index(drop=True)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.1, stratify=df[\"primary_genre\"], random_state=42\n",
        ")\n",
        "print(f\"Train: {len(train_df)} rows,  Val: {len(val_df)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnDZjszuY93e",
        "outputId": "80e9ec57-f186-45c3-c993-aa7276d070a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 32055 rows,  Val: 3562 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\w+'?\\w*|[.,!?;]\", text.lower())\n",
        "\n",
        "counter = Counter()\n",
        "for lyric in train_df[\"lyrics\"]:\n",
        "    counter.update(tokenize(lyric))\n",
        "vocab = {tok: i+2 for i, (tok, _) in enumerate(counter.most_common(20_000))}\n",
        "vocab[\"<pad>\"] = 0\n",
        "vocab[\"<unk>\"] = 1\n",
        "\n",
        "labels = sorted(train_df[\"primary_genre\"].unique())\n",
        "label2id = {lab: i for i, lab in enumerate(labels)}\n",
        "\n",
        "class LyricsDataset(Dataset):\n",
        "    def __init__(self, df, max_len=512):\n",
        "        self.texts = df[\"lyrics\"].tolist()\n",
        "        self.targets = [label2id[l] for l in df[\"primary_genre\"]]\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        toks = tokenize(self.texts[idx])[: self.max_len]\n",
        "        ids = [vocab.get(t, vocab[\"<unk>\"]) for t in toks]\n",
        "        return torch.tensor(ids, dtype=torch.long), self.targets[idx]\n",
        "\n",
        "def collate_batch(batch):\n",
        "    texts, labs = zip(*batch)\n",
        "    lengths = [len(x) for x in texts]\n",
        "    max_l = max(lengths)\n",
        "    padded = torch.zeros(len(texts), max_l, dtype=torch.long)\n",
        "    for i, x in enumerate(texts):\n",
        "        padded[i, : lengths[i]] = x\n",
        "    return padded, torch.tensor(labs)\n",
        "\n",
        "train_ds = LyricsDataset(train_df)\n",
        "val_ds   = LyricsDataset(val_df)\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "Of0Qp2N5aX2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTM_GRU_Classifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, padding_idx=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "        self.bilstm    = nn.LSTM(embed_dim, hidden_dim,\n",
        "                                 bidirectional=True, batch_first=True)\n",
        "        self.gru       = nn.GRU(2*hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.classifier= nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb, _ = self.bilstm(self.embedding(x))\n",
        "        out, _ = self.gru(emb)\n",
        "        feat    = out.mean(dim=1)\n",
        "        return self.classifier(feat)\n",
        "\n",
        "model_cls = BiLSTM_GRU_Classifier(\n",
        "    vocab_size=len(vocab), embed_dim=128, hidden_dim=256, num_classes=len(labels)\n",
        ").to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "Rpc7bFAzag57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = optim.Adam(model_cls.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model_cls.train() if train else model_cls.eval()\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for x, y in tqdm(loader, desc=\"Train\" if train else \"Val\"):\n",
        "        x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
        "        logits = model_cls(x)\n",
        "        loss = criterion(logits, y)\n",
        "        if train:\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_acc  += (logits.argmax(1)==y).sum().item()\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss/n, total_acc/n\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
        "    vl_loss, vl_acc = run_epoch(val_loader,   train=False)\n",
        "    print(f\"Epoch {epoch} → train {tr_loss:.3f}/{tr_acc:.3f},  val {vl_loss:.3f}/{vl_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AicYfheeamkC",
        "outputId": "d350168d-b476-4d12-a3e8-c5ad4fa7511d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1002/1002 [00:56<00:00, 17.69it/s]\n",
            "Val: 100%|██████████| 112/112 [00:03<00:00, 34.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 → train 2.260/0.501,  val 2.064/0.520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1002/1002 [00:55<00:00, 17.93it/s]\n",
            "Val: 100%|██████████| 112/112 [00:03<00:00, 34.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 → train 1.936/0.538,  val 1.913/0.543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1002/1002 [00:55<00:00, 17.91it/s]\n",
            "Val: 100%|██████████| 112/112 [00:03<00:00, 34.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 → train 1.734/0.566,  val 1.852/0.546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1002/1002 [00:56<00:00, 17.86it/s]\n",
            "Val: 100%|██████████| 112/112 [00:03<00:00, 34.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 → train 1.510/0.605,  val 1.898/0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1002/1002 [00:56<00:00, 17.84it/s]\n",
            "Val: 100%|██████████| 112/112 [00:03<00:00, 34.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 → train 1.225/0.668,  val 2.024/0.531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_cls.state_dict(), \"/content/drive/MyDrive/NLP/bilstm_gru_classifier_100.pt\")"
      ],
      "metadata": {
        "id": "L9l_aBQFao_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSdA77IaQfVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}